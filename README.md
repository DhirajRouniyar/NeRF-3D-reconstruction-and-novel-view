# NeRF-3D-reconstruction-and-novel-view
In this project, we will provide a comprehensive analysis of our implementation of the NeRF network. NERF, short for Neural Radiance Fields, embodies a sophisticated framework encapsulated within a fully connected network architecture. This neural network operates seamlessly, with its input characterized by a unified continuous 5D coordinate system, encompassing spatial positions denoted by (x, y, z), coupled with viewing directions represented by (θ, ψ) and provides the volume density and the RGB pixel values corresponding precisely to the provided viewing direction as outputs. We use the lego and the ship dataset from the official dataset obtained from the original author.
Please refer the [report](https://pages.github.com/) for detailed information including steps, outputs and losses.

# Model Architecture
We have used the network mentioned in the official NeRF paper but we have only used one network instead of both coarse and fine networks. The architecture can be seen in below figure. The implementation is a fully connected network and has hidden layers with 256 channels each and a ReLU after it. After 4 layers, there is a skip connection that concatenates the input to the fifth layer. An additional layer outputs the density and is then concatenated with the viewing direction. It is then processed by an additional fully connected layer with 128 channels which gives the RGB output. For dataloading, we read all the images of the train or test set provided and convert them to a lower resolution (200,200) for faster computation. We then generate rays for all the images, convert them to 2D tensors and provide them to the torch dataloader which will provide all the values according to the batch size as an input for the network. In the network, firstly, all sample points are calculated for each ray provided by the dataloader, positional encoding is done and then the data is given to the network. The MSE loss function is used to calculate the loss based on the output generated by the network. Renderer is used to render the output generated by the network.
• Number of samples per ray: 256
• Learning rate: 0.0005
• Optimizer: Adam
• Loss: MSE loss
• Near, Far bounds: 2, 6
![](https://github.com/DhirajRouniyar/NeRF-3D-reconstruction-and-novel-view/blob/main/Images/Network.png)

# Output_1
![](https://github.com/DhirajRouniyar/NeRF-3D-reconstruction-and-novel-view/blob/main/Phase%202/Nerf.gif)

# Output_2
![](https://github.com/DhirajRouniyar/NeRF-3D-reconstruction-and-novel-view/blob/main/Phase%202/Nerf_2.gif)
