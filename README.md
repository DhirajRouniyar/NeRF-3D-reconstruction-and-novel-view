# NeRF-3D-reconstruction-and-novel-view
# Model Architecture
We have used the network mentioned in the official NeRF paper but we have only used one network instead of both coarse and fine networks. The architecture can be seen in below figure. The implementation is a fully connected network and has hidden layers with 256 channels each and a ReLU after it. After 4 layers, there is a skip connection that concatenates the input to the fifth layer. An additional layer outputs the density and is then concatenated with the viewing direction. It is then processed by an additional fully connected layer with 128 channels which gives the RGB output. For dataloading, we read all the images of the train or test set provided and convert them to a lower resolution (200,200) for faster computation. We then generate rays for all the images, convert them to 2D tensors and provide them to the torch dataloader which will provide all the values according to the batch size as an input for the network. In the network, firstly, all sample points are calculated for each ray provided by the dataloader, positional encoding is done and then the data is given to the network. The MSE loss function is used to calculate the loss based on the output generated by the network. Renderer is used to render the output generated by the network.
• Number of samples per ray: 256
• Learning rate: 0.0005
• Optimizer: Adam
• Loss: MSE loss
• Near, Far bounds: 2, 6
![](https://github.com/DhirajRouniyar/NeRF-3D-reconstruction-and-novel-view/blob/main/Phase%202/Nerf.gif)

# Output_1
![](https://github.com/DhirajRouniyar/NeRF-3D-reconstruction-and-novel-view/blob/main/Phase%202/Nerf.gif)

# Output_2
![](https://github.com/DhirajRouniyar/NeRF-3D-reconstruction-and-novel-view/blob/main/Phase%202/Nerf_2.gif)
